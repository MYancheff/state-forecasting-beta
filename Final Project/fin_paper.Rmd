---
title: "Modeling"
output: github_document
---


```{r load_everything, echo=FALSE}
library(foreign)
library(tidyverse)
library(lubridate)
library(rpart)
library(ggthemes)
library(Amelia)
library(mice)
library(data.table)

precinct_data_all = read_csv("Nevada General Election Precinct Level Voting Results 1984-2016.csv")
source("load_carls.R")
source("load_precinct_data.R")
source("load_econ_data.R")
```

```{r district_level_data, echo=FALSE}
pres_summary = precinct_data_all %>% 
  filter(OFFICENAME %in% c("president","governor")) %>%
  filter(!is.na(VOTES)) %>%
  group_by(OFFICENAME,YEAR,STATE_LEGISLATIVE_CHAMBER,DIST_NAME,DISTRICT_NUM,PARTY_CODE) %>%
  summarise(vote_count = sum(VOTES),
            Party = get_pres_gov_party(PARTY_CODE[1])) %>%
  summarise(vote_dem = sum(ifelse(PARTY_CODE=="DEM",vote_count,0)),
            total_vote = sum(vote_count)) %>%
  ungroup() %>%
  gather(key=value_type,value=vote_value,vote_dem:total_vote)%>%
  unite(RaceValue,OFFICENAME,value_type) %>%
  spread(RaceValue,vote_value) %>%
  # deals with werid zeros by remoing them
  mutate(governor_vote_dem = ifelse(governor_vote_dem == 0,NA,governor_vote_dem))
  
  
named_data = pres_summary %>% 
  mutate(DISTRICT_NUM = ifelse(is.na(DISTRICT_NUM),1,DISTRICT_NUM)) %>%
  filter()

joined_named_data = use_data %>%
  left_join(named_data,
            by=c("ELECTION_YEAR"="YEAR","Assembly"="STATE_LEGISLATIVE_CHAMBER","DISTRICT_NUM"="DISTRICT_NUM","DISTRICT_NAME"="DIST_NAME")) %>%
  filter(Assembly == "SENATE" & ELECTION_YEAR < 2012)

unnamed_data = pres_summary %>% 
  select(-DIST_NAME)

joined_unnamed_data = use_data %>%
  left_join(unnamed_data,
            by=c("ELECTION_YEAR"="YEAR","Assembly"="STATE_LEGISLATIVE_CHAMBER","DISTRICT_NUM"="DISTRICT_NUM")) %>%
  filter(!(Assembly == "SENATE" & ELECTION_YEAR < 2012))

district_level_data = rbind(joined_named_data,joined_unnamed_data) %>%
  mutate(party_val = ifelse(wining_party == "DEM",1,
                            ifelse(wining_party == "REP",-1,0)),
         governor_perc_vote_dem = governor_vote_dem/governor_total_vote,
         president_perc_vote_dem =
           president_vote_dem/president_total_vote) %>%
  select(-(governor_total_vote:president_vote_dem))
```

```{r state_level_data,echo=FALSE}
pres_party_in_power_data = read_csv("state-legislative-data/pres_in_power.csv")

state_level_data = economic_data %>%
  left_join(pres_party_in_power_data,by=c("YEAR"="year")) %>%
  
  # spread party_in_power variable over all the years they are in power, not just every 4 years
  group_by((YEAR-1) %/% 4) %>%
  mutate(pres_party_in_power = paste(ifelse(is.na(pres_party_in_power),"",pres_party_in_power),collapse="")) %>%
  ungroup() %>%
  
  #calculate midterm and presidentail election penalties
  mutate(is_midterm = (YEAR %% 4) == 2,
         is_pres_election = (YEAR %% 4) == 0,
         pres_party_num = ifelse(pres_party_in_power=="DEM",1,
                                 ifelse(pres_party_in_power=="REP",-1,0)),
         midterm_penalty = pres_party_num * is_midterm,
         pres_elect_penalty = pres_party_num * is_pres_election) %>%
  
  select(YEAR:Unemployment_LOCAL,midterm_penalty,pres_elect_penalty) %>%
  mutate(lag_MHI_Change_LOCAL = lag(MHI_Change_LOCAL,order_by=YEAR))
```

```{r assembly_level_summary,echo=FALSE}
year_summary = district_level_data %>%
  group_by(Assembly,ELECTION_YEAR) %>%
  summarise(assembly_composition = sum(party_val)/n()) %>%
  mutate(lag_assembly_composition = lag(assembly_composition,order_by=ELECTION_YEAR)) %>%
  ungroup()
```

```{r,echo=FALSE}
joined_district_data = district_level_data %>%
  left_join(year_summary ,by=c("ELECTION_YEAR","Assembly")) %>%
  left_join(state_level_data ,by=c("ELECTION_YEAR"="YEAR")) %>%
  mutate(DIST_ID = factor(paste(DISTRICT_NAME,DISTRICT_NUM))) %>%
  select(-DISTRICT_NUM,-DISTRICT_NAME)
```


```{r,echo=FALSE}
lagged_district_data = joined_district_data %>%
  group_by(Assembly,DIST_ID) %>%
  #lagged by one year entry (i.e. 2 years for house, 4 years for senate)
  mutate(lag_governor_perc_vote_dem = lag(governor_perc_vote_dem,order_by=ELECTION_YEAR),
         lag_president_perc_vote_dem = lag(president_perc_vote_dem,order_by=ELECTION_YEAR),
         lag_assembly_vote_dem = lag(assembly_vote_dem,order_by=ELECTION_YEAR),
         lag_incumbent_factor = lag(incumbent_factor,order_by=ELECTION_YEAR)) %>%
  ungroup()
```

```{r impute_missing,echo=FALSE}
impute_data = function(all_data){
  mice_imputed_data = complete( mice( all_data ,printFlag=FALSE,m=1))
  
  
  # conducts amelia imputation
  #removed_amelia_cols = all_data %>%
  #  select(DIST_ID,Assembly,wining_party,party_val,pres_elect_penalty,has_incumbent,lag_has_incumbent)
  
  #amelia_data = all_data %>%
  #  select(-DIST_ID,-Assembly,-wining_party,-party_val,-pres_elect_penalty,-has_incumbent,-lag_has_incumbent)
  
  #amelia_fit <- amelia(amelia_data,
  #                     m=1,
  #                     p2s=0,#2 is verbose, 1 is not as verbose, 0 is no output
  #                     ts="ELECTION_YEAR")
  #amelia_imputed_data = cbind(amelia_fit$imputations[[1]],removed_amelia_cols)
  
  #check if mice_imputed_data or amelia_imputed_data works better
  
  mice_imputed_data
}
zero_off_election_years = function(data){
  data %>%
  mutate(governor_perc_vote_dem = 
           ifelse(ELECTION_YEAR %% 4 == 2,governor_perc_vote_dem,0),
         president_perc_vote_dem =
           ifelse(ELECTION_YEAR %% 4 == 0,president_perc_vote_dem,0),
         lag_governor_perc_vote_dem = ifelse(ELECTION_YEAR %% 4 == 0,lag_governor_perc_vote_dem,0),
         lag_president_perc_vote_dem = ifelse(ELECTION_YEAR %% 4 == 2,lag_president_perc_vote_dem,0))
}
```


```{r,echo=FALSE}
place_has_incumbent = function(data){
  data %>%
    mutate(has_incumbent = ifelse(incumbent_factor==0,0,1),
           lag_has_incumbent = ifelse(lag_incumbent_factor==0,0,1))
}
linear_model_acc = function(train_data,test_data){
  model = lm(assembly_composition ~ 
       #state level data
       lag_assembly_composition*GDPperCapita_CHANGE_US + 
       MHI_Change_LOCAL +
       lag_MHI_Change_LOCAL +
       GDPperCapita_CHANGE_US + 
       midterm_penalty + 
       pres_elect_penalty + 
        
       # district level variables
       incumbent_factor + 
       lag_incumbent_factor + 
       lag_governor_perc_vote_dem + 
       lag_president_perc_vote_dem + 
       lag_assembly_vote_dem
       ,data=train_data)
  
  guessed_outcome = predict(model,test_data,type = "response")
  actual_outcome = test_data$assembly_composition
  ms_error = sqrt(sum((guessed_outcome-actual_outcome)^2)/nrow(test_data))
  mean((guessed_outcome+1)/2)
}
probit_model_acc = function(train_data,test_data){
  model = glm((party_val+1)/2 ~
       #state level data
       lag_assembly_composition*GDPperCapita_CHANGE_US + 
       MHI_Change_LOCAL +
       lag_MHI_Change_LOCAL +
       GDPperCapita_CHANGE_US + 
       midterm_penalty + 
       pres_elect_penalty + 
        
       # district level variables
       incumbent_factor + 
       lag_incumbent_factor + 
       (lag_governor_perc_vote_dem + 
       lag_president_perc_vote_dem + 
       lag_assembly_vote_dem) * has_incumbent
       ,data=train_data
       ,family="binomial")
  guessed_outcome = predict(model,test_data,type = "response")
  discrete_guessed_outcome = ifelse(guessed_outcome>0.5,1,0)
  actual_outcome = (test_data$party_val+1)/2
  
  miscalc_rate = sum(ifelse(discrete_guessed_outcome != actual_outcome,1,0))/nrow(test_data)
  sum(discrete_guessed_outcome)/nrow(test_data)
}
get_model_accuracy = function(assembly_data,model_acc,testyear){
  train_data = assembly_data %>%
    filter(ELECTION_YEAR < testyear) %>%
    impute_data() %>%
    # needs to happen after imputation or else the imputation is terreble
    zero_off_election_years()
  
  test_data = assembly_data %>%
    impute_data() %>%
    filter(ELECTION_YEAR == testyear) %>%
    zero_off_election_years() 
  
  model_acc(train_data,test_data)
}
testyear = 2014
get_accuracies = function(assembly_data,generate_model_fn){
  years = assembly_data %>%
    select(ELECTION_YEAR) %>%
    distinct()
  estimate_years = years$ELECTION_YEAR[years$ELECTION_YEAR > 1996]
  accuracies = sapply(estimate_years,function(test_year){
    get_model_accuracy(assembly_data,generate_model_fn,test_year)
  })
  possible_elections = sapply(estimate_years,function(test_year){
    nrow(assembly_data %>%
      filter(ELECTION_YEAR == test_year))
  }) 
  data.frame(accuracies,estimate_years,possible_elections)
}
get_assembly_data = function(assembly){
  start_year = 1986
  assembly_data = lagged_district_data %>%
    filter(Assembly==assembly,
           ELECTION_YEAR>=start_year) %>%
    place_has_incumbent()
}
```



```{r,echo=FALSE}
num_samples = 8
all_accuracies_house = rbindlist(lapply(1:num_samples,function(n)get_accuracies(get_assembly_data("HOUSE"))))
all_accuracies_senate = rbindlist(lapply(1:num_samples,function(n)get_accuracies(get_assembly_data("SENATE"))))
```

```{r,echo=FALSE}
all_accuracies_house$Assembly="HOUSE"
all_accuracies_senate$Assembly="SENATE"
all_accuracies = rbind(all_accuracies_house,all_accuracies_senate)
ggplot(all_accuracies,aes(x=estimate_years,y=accuracies/possible_elections,color=Assembly)) +
  geom_point() + 
  geom_smooth()
```



# Modeling State Legislative Elections In Nevada

Nevada is a politically volitile state, with the state legislature changing every couple of years recently.

```{r,echo=FALSE,warning=FALSE}
zero_intercept_years = year_summary %>%
  group_by(Assembly) %>%
  mutate(m = (assembly_composition-lag(assembly_composition,order_by=ELECTION_YEAR))/(ELECTION_YEAR-lag(ELECTION_YEAR,order_by=ELECTION_YEAR)),
         b = assembly_composition - m * ELECTION_YEAR,
         x_cross = -b/m) %>%
  filter(x_cross > lag(ELECTION_YEAR,order_by=ELECTION_YEAR) & x_cross < ELECTION_YEAR) %>%
  ungroup() %>%
  mutate(ELECTION_YEAR=x_cross,
         assembly_composition=0) %>%
  select(ELECTION_YEAR,assembly_composition,Assembly)

plot_chart_use_data = year_summary %>%
  select(-lag_assembly_composition) %>%
  rbind(zero_intercept_years) %>%
  arrange(ELECTION_YEAR)

argvar = data.frame(YEAR=c(min(plot_chart_use_data$ELECTION_YEAR),max(plot_chart_use_data$ELECTION_YEAR)),party_composition=c(0.5,0.5))

plot_chart_use_data %>%
  mutate(assembly_composition = assembly_composition*0.5 + 0.5,
         dem_years = assembly_composition,
         rep_years = 1-assembly_composition) %>%
  gather(dem_years,rep_years,key=party_year,value=party_composition) %>%
  ggplot(aes(x=ELECTION_YEAR,y=party_composition,fill=party_year)) + 
    geom_area(position="stack") + 
    facet_grid(~Assembly) + 
    geom_line(data=argvar,mapping=aes(x=YEAR,y=party_composition,fill=NA),color="black") + 
    theme_few() + 
    xlab("Year") + 
    ylab("Party control of assembly") + 
    ggtitle("Nevada State Legislature Party Composition over Time") + 
    scale_fill_manual(values=c("blue","red"),
                      labels=c("Democratic","Republican"),
                      guide = guide_legend(title = "Party"))
    
```

We want to model state legislative elections, so that we can predict future election results. In particular, the most important result people usually want to know is the party composition of the state legislatures, as this can determine the policy agenda for the state. 

Unfortunately, forecasting state legislative elections is difficult. There is a lot of unobserved characteristics especially at the district level, with certain candidates being of better qualities than others, or particular features of the districts at hand. 

Unfortunatly, in Nevada there has been a lot of redistricting, and a lack of precinct level maps that would allow us to account for this by performing a geographic join. Without those maps, we cannot account for unobserved variables in districts by tracking them over a long period of time. 

So we need to gather as much information about a district as possible. For example, one clearly useful variable is the extent to which the canidate of the Democratic party won in the prior year. Another one is whether that canidate was an incumbent or not, and whether they are running again in the upcoming election.

We also gathered several variables at the state and national level, including economic variables such as GDP and median household income, several policial variables such as the party of the president, and governor, and the state legislative composition in the previous year.


### Data Tidying and Joining

The format of the tidied dataset we want to model is this:

Every row is a (Year, Assembly, District) triple. This is a nice unit because it is the unit we want to run models on. However, none of our data is in this form. All of our data is in a (Year, Canidate) format. So in each dataset, before joining, we need to summarize the sort of covariates we want from that bit of candidate level data.

### Lagging variables

Most of the useful information about the districts (e.g. voting results) cannot being predicted for the current election, and so it must be taken from the previous eleciton. In years other than redistricing years, this is a very simple matter. In redistricting years, ideally we would have kept all the 

### Multiple Imputation

Much of our data was missing. In order to fit a model, we needed to fill in this data. I considered mean and median, however, these seriously reduced the quality of the model. I also tried to use Amelia II, via R's Amelia package. However, this was extremely fiddly, as it does not work with colinear variables, and it also assumes that values are pulled from a multivariate normal distribution. I also could not get its catagorical variable feature working. So I chose to use R's MICE package, which can work with a wide variety of data, and it seemed to work amazingly well out of the box.  

### Modeling Level

Two of the simplest ways of predicting state legislative composition are these:

* A simple linear model. The outcome (percentage of Democrats in the legislature) is fit as a simple linear function of the known variables. 
* A logit model. The outcome of each district is fit as a logit model of which party won. Then we can predict who will win at the district level by which party has over 50% probabilty of winning. 

## Quality of Covariates

Even before modeling, we can at least attempt to see which covariates are important. The one we are the most interested in is the 

```{r,echo=FALSE,fig.width=6,fig.height=20}
na_to_zero = function(val)ifelse(is.na(val),0,val)

y2016_dat = filter(lagged_district_data,ELECTION_YEAR==2016)
lagged_district_data %>%
  mutate(elect_type= ifelse(ELECTION_YEAR %% 4 == 2,"President","Governor"),
         lag_vote_dem = na_to_zero(lag_governor_perc_vote_dem)+na_to_zero(lag_president_perc_vote_dem)) %>%
  filter(#abs(assembly_vote_dem) != 1,
         lag_vote_dem != 0) %>%
  ggplot(aes(y=lag_vote_dem,x=assembly_vote_dem/2+0.5))+
  geom_smooth(method="lm") + 
  geom_point() + 
  ggtitle("Predictive Power of President Vote Composition on State Legislative Vote at the District Level") + 
  ylab("Percent vote for Republican State Legislator") + 
  xlab("Percent vote for Republican President in previous election") + 
  facet_grid(ELECTION_YEAR~elect_type)
```

## Actual Predictive Results

### Train/Test Method

In order to make sure that the model actually works, I tested it on previous years, by running the following algorithm.

Given a particular test year, 

1. Filter out prior years from dataset
2. Conduct imputation on filtered dataset
3. Train model on that imputed dataset
4. Predict outcome with that model
5. Compare that outcome with the actual outcome

And then I ran that for several years prior to 2016. 

Here are some results from that method:

```{r model_data,echo=FALSE}

assembly_data = get_assembly_data("HOUSE")

probit_acccs = get_accuracies(assembly_data,probit_model_acc)
linear_acccs = get_accuracies(assembly_data,linear_model_acc)

act_data = year_summary %>%
  filter(ELECTION_YEAR> 1996,
         Assembly=="HOUSE") %>%
  mutate(actual_data = (1+assembly_composition)/2) %>%
  select(ELECTION_YEAR,actual_data)

act_data$linear_fit = linear_acccs$accuracies
act_data$logit_fit = probit_acccs$accuracies

act_data %>%
  gather(key=fit_type,value=senate_comp_value,-ELECTION_YEAR) %>%
  ggplot(aes(x=ELECTION_YEAR,y=senate_comp_value,color=fit_type))+
    geom_line() + 
    scale_y_continuous(limits = c(0,1.7))

```

As you can see, while the model sometimes correctly guesses changes in electoral composition, it leaves a lot to be desired. However, the two different models are wrong in different placces, suggesting that there is a a way to combine their results in a way that is more accurate than either. 

Also note that the MICE imputation method is randomized, which creates variance in our prediction. Unfortunatly, it is also slow enough that measuring this variance numerically is impractical (a single run takes about a two minutes).


